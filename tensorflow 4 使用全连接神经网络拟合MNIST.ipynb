{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "iter0,testing accuracy0.8297\n",
      "iter1,testing accuracy0.8705\n",
      "iter2,testing accuracy0.8824\n",
      "iter3,testing accuracy0.8882\n",
      "iter4,testing accuracy0.8946\n",
      "iter5,testing accuracy0.8966\n",
      "iter6,testing accuracy0.8999\n",
      "iter7,testing accuracy0.9016\n",
      "iter8,testing accuracy0.9036\n",
      "iter9,testing accuracy0.9054\n",
      "iter10,testing accuracy0.9064\n",
      "iter11,testing accuracy0.9074\n",
      "iter12,testing accuracy0.9083\n",
      "iter13,testing accuracy0.9087\n",
      "iter14,testing accuracy0.9098\n",
      "iter15,testing accuracy0.9109\n",
      "iter16,testing accuracy0.9118\n",
      "iter17,testing accuracy0.9125\n",
      "iter18,testing accuracy0.9126\n",
      "iter19,testing accuracy0.9133\n",
      "iter20,testing accuracy0.9142\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "#二次代价函数训练MNIST\n",
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "Weight = tf.Variable(tf.zeros([784,10]))\n",
    "bias = tf.Variable(tf.zeros([1,10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weight)+bias)\n",
    "\n",
    "#二次代价函数 loss指标表示模型的好壞\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值所在的位置\n",
    "#计算准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\"+str(epoch)+\",testing accuracy\"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "iter0,testing accuracy0.8249\n",
      "iter1,testing accuracy0.8923\n",
      "iter2,testing accuracy0.9011\n",
      "iter3,testing accuracy0.9056\n",
      "iter4,testing accuracy0.9089\n",
      "iter5,testing accuracy0.9101\n",
      "iter6,testing accuracy0.9113\n",
      "iter7,testing accuracy0.913\n",
      "iter8,testing accuracy0.9144\n",
      "iter9,testing accuracy0.9154\n",
      "iter10,testing accuracy0.9172\n",
      "iter11,testing accuracy0.9189\n",
      "iter12,testing accuracy0.9183\n",
      "iter13,testing accuracy0.919\n",
      "iter14,testing accuracy0.9203\n",
      "iter15,testing accuracy0.9199\n",
      "iter16,testing accuracy0.9202\n",
      "iter17,testing accuracy0.9204\n",
      "iter18,testing accuracy0.9204\n",
      "iter19,testing accuracy0.9212\n",
      "iter20,testing accuracy0.9218\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "#不改变激活函数，改用交叉熵代价函数，同时配合tensorboard\n",
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#命名空间\n",
    "with tf.name_scope('input'):\n",
    "    #定义两个placeholder\n",
    "    x=tf.placeholder(tf.float32,[None,784],name='x-input')\n",
    "    y=tf.placeholder(tf.float32,[None,10],name='y-input')\n",
    "\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        Weight = tf.Variable(tf.zeros([784,10]),name='w')\n",
    "    with tf.name_scope('biases'):\n",
    "        bias = tf.Variable(tf.zeros([1,10]),name='b')\n",
    "    with tf.name_scope('prediction'):\n",
    "        prediction = tf.nn.softmax(tf.matmul(x,Weight)+bias)\n",
    "\n",
    "#交叉熵,加快模型的收敛速度\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y,logits=prediction))\n",
    "with tf.name_scope('train'):\n",
    "    #使用梯度下降法\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        #结果存放在一个布尔型列表中\n",
    "        correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值所在的位置\n",
    "    with tf.name_scope('accuracy'):\n",
    "        #计算准确率\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('logs/',sess.graph)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\"+str(epoch)+\",testing accuracy\"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "iter0,testing accuracy0.9307,training accuracy0.92794544\n",
      "iter1,testing accuracy0.9451,training accuracy0.9473091\n",
      "iter2,testing accuracy0.9527,training accuracy0.9575091\n",
      "iter3,testing accuracy0.9565,training accuracy0.96287274\n",
      "iter4,testing accuracy0.9599,training accuracy0.96867275\n",
      "iter5,testing accuracy0.9645,training accuracy0.9736\n",
      "iter6,testing accuracy0.9662,training accuracy0.97654545\n",
      "iter7,testing accuracy0.9671,training accuracy0.979\n",
      "iter8,testing accuracy0.9704,training accuracy0.98138183\n",
      "iter9,testing accuracy0.9698,training accuracy0.98350906\n",
      "iter10,testing accuracy0.9706,training accuracy0.9846727\n",
      "iter11,testing accuracy0.9724,training accuracy0.98614544\n",
      "iter12,testing accuracy0.972,training accuracy0.9870909\n",
      "iter13,testing accuracy0.9741,training accuracy0.98809093\n",
      "iter14,testing accuracy0.9728,training accuracy0.9884\n",
      "iter15,testing accuracy0.9742,training accuracy0.98932725\n",
      "iter16,testing accuracy0.974,training accuracy0.98956364\n",
      "iter17,testing accuracy0.9747,training accuracy0.9903455\n",
      "iter18,testing accuracy0.975,training accuracy0.99078184\n",
      "iter19,testing accuracy0.9764,training accuracy0.9911091\n",
      "iter20,testing accuracy0.9755,training accuracy0.99145454\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot = True)\n",
    "\n",
    "#增加中间层和dropout，模拟过拟合情况\n",
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "Weight_L1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "bias_L1 = tf.Variable(tf.zeros([500])+0.1)\n",
    "L1 = tf.nn.tanh(tf.matmul(x,Weight_L1)+bias_L1)\n",
    "L1_drop = tf.nn.dropout(L1,keep_prob)\n",
    "\n",
    "Weight_L2 = tf.Variable(tf.truncated_normal([500,300],stddev=0.1))\n",
    "bias_L2 = tf.Variable(tf.zeros([300])+0.1)\n",
    "L2 = tf.nn.tanh(tf.matmul(L1_drop,Weight_L2)+bias_L2)\n",
    "L2_drop = tf.nn.dropout(L2,keep_prob)\n",
    "\n",
    "Weight_L3 = tf.Variable(tf.truncated_normal([300,100],stddev=0.1))\n",
    "bias_L3 = tf.Variable(tf.zeros([100])+0.1)\n",
    "L3 = tf.nn.tanh(tf.matmul(L2_drop,Weight_L3)+bias_L3)\n",
    "L3_drop = tf.nn.dropout(L3,keep_prob)\n",
    "\n",
    "Weight_L4 = tf.Variable(tf.truncated_normal([100,10],stddev=0.1))\n",
    "bias_L4 = tf.Variable(tf.zeros([10])+0.1)\n",
    "\n",
    "#输出层不在有drop_out\n",
    "prediction = tf.nn.softmax(tf.matmul(L3_drop,Weight_L4)+bias_L4)\n",
    "\n",
    "#交叉熵代价函数\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值所在的位置\n",
    "#计算准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep_prob:1.0})\n",
    "            \n",
    "        testing_acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep_prob:1.0})\n",
    "        training_acc = sess.run(accuracy,feed_dict={x:mnist.train.images,y:mnist.train.labels,keep_prob:1.0})\n",
    "        print(\"iter\"+str(epoch)+\",testing accuracy\"+str(testing_acc)+\",training accuracy\"+str(training_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter0,testing accuracy0.9211\n",
      "iter1,testing accuracy0.9258\n",
      "iter2,testing accuracy0.9291\n",
      "iter3,testing accuracy0.9269\n",
      "iter4,testing accuracy0.9283\n",
      "iter5,testing accuracy0.9304\n",
      "iter6,testing accuracy0.9258\n",
      "iter7,testing accuracy0.9289\n",
      "iter8,testing accuracy0.9312\n",
      "iter9,testing accuracy0.9303\n",
      "iter10,testing accuracy0.9317\n",
      "iter11,testing accuracy0.9298\n",
      "iter12,testing accuracy0.9314\n",
      "iter13,testing accuracy0.9337\n",
      "iter14,testing accuracy0.9318\n",
      "iter15,testing accuracy0.9316\n",
      "iter16,testing accuracy0.9329\n",
      "iter17,testing accuracy0.9316\n",
      "iter18,testing accuracy0.9333\n",
      "iter19,testing accuracy0.9321\n",
      "iter20,testing accuracy0.9305\n"
     ]
    }
   ],
   "source": [
    "#定义每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "Weight = tf.Variable(tf.zeros([784,10]))\n",
    "bias = tf.Variable(tf.zeros([1,10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,Weight)+bias)\n",
    "\n",
    "#交叉熵\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n",
    "#优化器\n",
    "train_step = tf.train.AdamOptimizer(0.01).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#结果存放在一个布尔型列表中\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大值所在的位置\n",
    "#计算准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        print(\"iter\"+str(epoch)+\",testing accuracy\"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
